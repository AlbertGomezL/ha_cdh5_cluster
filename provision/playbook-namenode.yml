---
- hosts: all
  become: true
  tasks:
        
    - name: Crear usuario hadoop
      user:
        name: hadoop
        password: '*'
        state: present
    
    - name: Crear directorio ssh
      file:
        path: /home/hadoop/.ssh
        state: directory
        
    - name: Configurar clave privada
      copy:
        src: clave_hadoop
        dest: /home/hadoop/.ssh/id_rsa
          
    - name: Update APT package manager repositories cache
      apt:
        update_cache: yes
        
    - name: Install required packages
      apt:
        update_cache: yes
        name: "{{ packages }}"
        state: present
      vars:
        packages:
          - openjdk-7-jre-headless
          - openssh-client
          - rsync
          - wget
          - sshpass
         
    - name: Configurar hosts
      copy:
        src: hosts
        dest: /etc/hosts
        
    - name: Download CDH5 package
      get_url:
        url: http://archive.cloudera.com/cdh5/one-click-install/precise/amd64/cdh5-repository_1.0_all.deb
        dest: /vagrant
        force_basic_auth: yes

    - name: Install cdh5-repository.deb
      apt:
        deb: /vagrant/cdh5-repository_1.0_all.deb

    - name: Add Cloudera repository key
      apt_key:
        url: http://archive.cloudera.com/cdh5/ubuntu/precise/amd64/cdh/archive.key

    - name: Update apt packages
      apt:
        update_cache: yes
        force_apt_get: yes

    - name: Add hadoop to the path
      lineinfile:
        path: /home/hadoop/.profile
        line: PATH=/home/hadoop/hadoop/bin:/home/hadoop/hadoop/sbin:$PATH
        create: yes

    - name: Add hadoop to the shell path
      blockinfile:
        path: /home/hadoop/.bashrc
        block: |
          export HADOOP_HOME=/home/hadoop/hadoop
          export PATH=${PATH}:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin
        create: yes

    # - name: Add hadoop to the shell path II
    #   lineinfile:
    #     path: /home/hadoop/.bashrc
    #     line: export PATH=${PATH}:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin
    #     create: yes

    - name: Set java home
      lineinfile:
        path: /home/hadoop/etc/hadoop/hadoop-env.sh
        line: export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64/jre
        create: yes

    - name: Install Zookeeper
      apt: 
        name: zookeeper-server
        state: latest 

    - name: Creates zookeeper directory
      file:
        path: /var/lib/zookeeper
        state: directory

    - name: Set permissions
      command: chown -R zookeeper /var/lib/zookeeper/

    - name: Init zookeeper
      command: service zookeeper-server init --myid=1 --force
      
    - name: Start zookeeper service
      service:
        name: zookeeper-server
        state: started

    - name: Install jobtracker
      apt: 
        name: hadoop-0.20-mapreduce-jobtracker

    - name: Install namenode
      apt: 
        name: hadoop-hdfs-namenode      

    - name: Set namenode location
      blockinfile:
        path: /etc/hadoop/conf/core-site.xml
        block: |
            <property>
              <name>fs.default.name</name>
              <value>hdfs://namenode:9000</value>
            </property>
        insertbefore: </configuration>

    - name: Set path for HDFS
      blockinfile:
        path: /etc/hadoop/conf/core-site.xml
        block: |
          <property>
            <name>dfs.namenode.name.dir</name>
            <value>/home/hadoop/data/nameNode</value>
          </property>
          <property>
            <name>dfs.datanode.data.dir</name>
            <value>/home/hadoop/data/dataNode</value>
          </property>
          <property>
            <name>dfs.replication</name>
            <value>1</value>
          </property>
        insertbefore: </configuration>

    - name: Set yarn as job scheduler
      blockinfile:
        path: /etc/hadoop/conf/mapred-site.xml
        block: |
          <property>
            <name>mapreduce.framework.name</name>
            <value>yarn</value>
          </property>
          <property>
            <name>yarn.app.mapreduce.am.env</name>
            <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
          </property>
          <property>
            <name>mapreduce.map.env</name>
            <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
          </property>
          <property>
            <name>mapreduce.reduce.env</name>
            <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
          </property>
        insertbefore: </configuration>

    - name: Configure yarn
      blockinfile:
        path: /etc/hadoop/conf/mapred-site.xml
        block: |
          <property>
            <name>yarn.acl.enable</name>
            <value>0</value>
          </property>
          <property>
            <name>yarn.resourcemanager.hostname</name>
            <value>203.0.113.0</value>
          </property>
          <property>
            <name>yarn.nodemanager.aux-services</name>
            <value>mapreduce_shuffle</value>
          </property>
        insertbefore: </configuration>
      